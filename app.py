import streamlit as st
from googleapiclient.discovery import build
from datetime import datetime, timedelta
import pandas as pd
import isodate

# ====== UI è¨­å®š ======
st.set_page_config(page_title="YouTube Shorts ç†±é–€æœå°‹å™¨", layout="wide")
st.title("ğŸ¬ YouTube Shorts ç†±é–€æœå°‹å™¨ï¼ˆStreamlit ç‰ˆï¼‰")

# ====== å¿«å– YouTube æœå‹™ç‰©ä»¶ ======
@st.cache_resource
def get_youtube_service(api_key):
    return build('youtube', 'v3', developerKey=api_key)

# ====== å¿«å–å½±ç‰‡é¡åˆ¥ ======
@st.cache_data(show_spinner=False)
def get_video_categories(api_key, region_code='TW'):
    youtube = get_youtube_service(api_key)
    categories_response = youtube.videoCategories().list(
        part='snippet',
        regionCode=region_code
    ).execute()
    categories = {}
    for item in categories_response['items']:
        categories[item['id']] = item['snippet']['title']
    return categories

# ====== å·¥å…·å‡½æ•¸ ======
def get_time_filter(hours):
    if hours == "all":
        return None
    published_after = datetime.utcnow() - timedelta(hours=int(hours))
    return published_after.strftime('%Y-%m-%dT%H:%M:%SZ')

def format_duration(duration):
    try:
        parsed_duration = isodate.parse_duration(duration)
        total_seconds = int(parsed_duration.total_seconds())
        hours = total_seconds // 3600
        minutes = (total_seconds % 3600) // 60
        seconds = total_seconds % 60
        if hours > 0:
            return f"{hours}:{minutes:02d}:{seconds:02d}"
        else:
            return f"{minutes}:{seconds:02d}"
    except:
        return duration

def get_duration_seconds(duration):
    try:
        parsed_duration = isodate.parse_duration(duration)
        return int(parsed_duration.total_seconds())
    except:
        return 0

# ====== Sidebar æœå°‹æ¢ä»¶ ======
with st.sidebar:
    st.header("API Key è¨­å®š")
    api_key = st.text_input("è«‹è¼¸å…¥ YouTube API Key", type="password", help="éœ€å•Ÿç”¨ YouTube Data API v3")
    st.markdown("[å¦‚ä½•å–å¾— API Key?](https://console.cloud.google.com/)")

    st.header("æœå°‹æ¢ä»¶")
    keyword = st.text_input("é—œéµå­—", value="shorts", help="ç•™ç©ºä½¿ç”¨ shorts")
    category_filter = st.selectbox("å½±ç‰‡é¡åˆ¥", options=[
        ("all", "ä¸é™åˆ¶"),
        ("1", "é›»å½±èˆ‡å‹•ç•«"),
        ("2", "æ±½è»Šèˆ‡äº¤é€šå·¥å…·"),
        ("10", "éŸ³æ¨‚"),
        ("15", "å¯µç‰©èˆ‡å‹•ç‰©"),
        ("17", "é«”è‚²"),
        ("19", "æ—…éŠèˆ‡æ´»å‹•"),
        ("20", "éŠæˆ²"),
        ("22", "äººç‰©èˆ‡éƒ¨è½æ ¼"),
        ("23", "å–œåŠ‡"),
        ("24", "å¨›æ¨‚"),
        ("25", "æ–°èèˆ‡æ”¿æ²»"),
        ("26", "æ“ä½œèªªæ˜èˆ‡é¢¨æ ¼"),
        ("27", "æ•™è‚²"),
        ("28", "ç§‘å­¸èˆ‡æŠ€è¡“")
    ], index=0, format_func=lambda x: x[1])[0]
    region_filter = st.selectbox("åœ°å€", [
        "TW", "US", "JP", "KR", "CN", "HK", "SG", "IN", "GB", "DE", "FR", "NO", "CH", "DK", "AE", "SA", "MX", "CA", "AU", "RU"
    ], index=0)
    time_filter = st.selectbox("ä¸Šå‚³æ™‚é–“", [("all", "ä¸é™åˆ¶"), ("6", "6å°æ™‚å…§"), ("12", "12å°æ™‚å…§"), ("24", "24å°æ™‚å…§")], index=3, format_func=lambda x: x[1])[0]
    min_views = st.number_input("æœ€å°‘è§€çœ‹æ¬¡æ•¸", min_value=0, value=10000, step=1000)
    max_duration = st.selectbox("å½±ç‰‡é•·åº¦ï¼ˆç§’ï¼‰", [
        ("all", "ä¸é™åˆ¶"), ("5", "â‰¤ 5"), ("10", "â‰¤ 10"), ("15", "â‰¤ 15"), ("30", "â‰¤ 30"), ("60", "â‰¤ 60"),
        ("90", "â‰¤ 90"), ("120", "â‰¤ 120"), ("180", "â‰¤ 180")
    ], index=5, format_func=lambda x: x[1])[0]
    max_results = st.selectbox("çµæœæ•¸é‡", [10, 25, 50], index=1)

    st.markdown("---")
    search_btn = st.button("ğŸ” æœå°‹å½±ç‰‡")

# ====== æœå°‹ä¸¦é¡¯ç¤ºçµæœ ======
if search_btn:
    if not api_key or len(api_key) < 20:
        st.error("è«‹å…ˆè¼¸å…¥æœ‰æ•ˆçš„ YouTube Data API Keyã€‚")
        st.stop()
    try:
        youtube = get_youtube_service(api_key)
        categories = get_video_categories(api_key, region_code=region_filter)
        st.success(f"æˆåŠŸå–å¾— API èˆ‡é¡åˆ¥ï¼ˆå…± {len(categories)} å€‹é¡åˆ¥ï¼‰")
    except Exception as e:
        st.error(f"API Key éŒ¯èª¤æˆ–ç„¡æ³•é€£ç·š: {e}")
        st.stop()

    # æº–å‚™æœå°‹åƒæ•¸
    q = keyword.strip() if keyword.strip() else "shorts"
    search_params = {
        "part": "snippet",
        "q": q,
        "type": "video",
        "order": "relevance",
        "maxResults": min(50, max_results * 3),
        "regionCode": region_filter
    }
    lang_map = {"TW": "zh", "CN": "zh", "HK": "zh", "SG": "zh", "JP": "ja", "KR": "ko", "NO": "no", "CH": "de", "DE": "de", "DK": "da", "AE": "ar", "SA": "ar", "US": "en", "GB": "en", "CA": "en", "AU": "en", "IN": "en", "FR": "fr", "RU": "ru"}
    if region_filter in lang_map:
        search_params["relevanceLanguage"] = lang_map[region_filter]
    if category_filter != "all":
        search_params["videoCategoryId"] = category_filter
    if time_filter != "all":
        published_after = get_time_filter(time_filter)
        if published_after:
            search_params["publishedAfter"] = published_after

    # ====== æœå°‹å½±ç‰‡ ======
    with st.spinner("æ­£åœ¨æœå°‹å½±ç‰‡..."):
        try:
            search_response = youtube.search().list(**search_params).execute()
        except Exception as e:
            st.error(f"æœå°‹å¤±æ•—: {e}")
            st.stop()

    all_video_ids = []
    seen_ids = set()
    for item in search_response.get("items", []):
        video_id = item["id"]["videoId"]
        if video_id not in seen_ids:
            all_video_ids.append(video_id)
            seen_ids.add(video_id)

    # ä¸‹ä¸€é ï¼ˆå¦‚æœ‰éœ€è¦ï¼‰
    while len(all_video_ids) < min(max_results * 2, 50) and "nextPageToken" in search_response:
        search_params["pageToken"] = search_response["nextPageToken"]
        search_response = youtube.search().list(**search_params).execute()
        for item in search_response.get("items", []):
            video_id = item["id"]["videoId"]
            if video_id not in seen_ids and len(all_video_ids) < 50:
                all_video_ids.append(video_id)
                seen_ids.add(video_id)
        if len(all_video_ids) >= 50:
            break

    # å–å¾—å½±ç‰‡è©³ç´°è³‡æ–™
    batch_size = 50
    all_video_items = []
    for i in range(0, len(all_video_ids), batch_size):
        batch_ids = all_video_ids[i:i + batch_size]
        try:
            videos_response = youtube.videos().list(
                part="snippet,statistics,contentDetails",
                id=",".join(batch_ids)
            ).execute()
            all_video_items.extend(videos_response.get("items", []))
        except Exception as e:
            st.warning(f"éƒ¨ä»½å½±ç‰‡è©³æƒ…æŸ¥è©¢å¤±æ•—: {e}")

    # çµ„è£çµæœ
    videos = []
    for item in all_video_items:
        video_data = item["snippet"]
        statistics = item.get("statistics", {})
        content_details = item.get("contentDetails", {})
        view_count = int(statistics.get("viewCount", 0))
        if view_count < min_views:
            continue
        if max_duration != "all":
            duration_seconds = get_duration_seconds(content_details.get("duration", ""))
            if duration_seconds > int(max_duration):
                continue
        category_id = video_data.get("categoryId", "")
        category_name = categories.get(category_id, f'æœªçŸ¥é¡åˆ¥ ({category_id})')
        video_info = {
            "å½±ç‰‡ID": item["id"],
            "å½±ç‰‡æ¨™é¡Œ": video_data["title"],
            "é »é“åç¨±": video_data.get("channelTitle", ""),
            "é »é“ID": video_data.get("channelId", ""),
            "å½±ç‰‡é¡åˆ¥": category_name,
            "ä¸Šå‚³æ™‚é–“": video_data.get("publishedAt", ""),
            "è§€çœ‹æ¬¡æ•¸": view_count,
            "æŒ‰è®šæ•¸": int(statistics.get("likeCount", 0)),
            "ç•™è¨€æ•¸": int(statistics.get("commentCount", 0)),
            "å½±ç‰‡é•·åº¦": format_duration(content_details.get("duration", "")),
            "ç•«è³ª": content_details.get("definition", ""),
            "å­—å¹•": "æœ‰" if content_details.get("caption", "") == "true" else "ç„¡",
            "æˆæ¬Šå…§å®¹": "æ˜¯" if content_details.get("licensedContent", False) else "å¦",
            "å½±ç‰‡é€£çµ": f"https://www.youtube.com/watch?v={item['id']}",
            "å½±ç‰‡æè¿°": video_data.get("description", "")[:500],
            "æ¨™ç±¤": ", ".join(video_data.get("tags", [])) if video_data.get("tags") else "ç„¡",
            "ç¸®åœ–": video_data.get("thumbnails", {}).get("medium", {}).get("url", "")
        }
        videos.append(video_info)

    videos.sort(key=lambda x: x["è§€çœ‹æ¬¡æ•¸"], reverse=True)
    videos = videos[:max_results]

    st.subheader("æœå°‹çµæœ")
    if not videos:
        st.warning("æ‰¾ä¸åˆ°ç¬¦åˆæ¢ä»¶çš„å½±ç‰‡ï¼Œè«‹è©¦è©¦èª¿æ•´æ¢ä»¶ã€‚")
    else:
        for v in videos:
            colL, colR = st.columns([1, 4])
            with colL:
                if v["ç¸®åœ–"]:
                    st.image(v["ç¸®åœ–"], width=170)
            with colR:
                st.markdown(f"**[{v['å½±ç‰‡æ¨™é¡Œ']}]({v['å½±ç‰‡é€£çµ']})**")
                st.write(f"é »é“ï¼š{v['é »é“åç¨±']}ã€€|ã€€é¡åˆ¥ï¼š{v['å½±ç‰‡é¡åˆ¥']}ã€€|ã€€{v['å½±ç‰‡é•·åº¦']}ã€€|ã€€{v['è§€çœ‹æ¬¡æ•¸']}æ¬¡")
                st.caption(v["å½±ç‰‡æè¿°"])
            st.divider()

        # åŒ¯å‡º CSV
        csv_df = pd.DataFrame(videos)
        csv_bytes = csv_df.to_csv(index=False, encoding="utf-8-sig").encode("utf-8-sig")
        st.download_button(
            label="ğŸ“¥ åŒ¯å‡º CSV",
            data=csv_bytes,
            file_name=f"YouTube_shorts_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv"
        )
